{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLP_TP3_Graphs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK0qOkzJKjP2",
        "outputId": "1d084284-b8d6-430b-a59b-4137a486d78a"
      },
      "source": [
        "! pip install dgl           # For CPU Build\r\n",
        "! pip install dgl-cu101     # For CUDA 10.1 Build\r\n",
        "\r\n",
        "# Do not forget to put manually colab in gpu mode"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dgl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/62/da7146c0e46f93dd1f17cccea3010def155a1f479c0b036b604e952f321f/dgl-0.5.3-cp36-cp36m-manylinux1_x86_64.whl (3.6MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6MB 19.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.19.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl) (4.4.2)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.5.3\n",
            "Collecting dgl-cu101\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/08/ea2d56e85eba1c22a14fa0f9b3c4ca8b43bf07de34e454d4e23632b376ea/dgl_cu101-0.5.3-cp36-cp36m-manylinux1_x86_64.whl (25.0MB)\n",
            "\u001b[K     |████████████████████████████████| 25.0MB 133kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl-cu101) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl-cu101) (1.19.5)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl-cu101) (2.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from dgl-cu101) (2.23.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl-cu101) (4.4.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl-cu101) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl-cu101) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl-cu101) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl-cu101) (1.24.3)\n",
            "Installing collected packages: dgl-cu101\n",
            "Successfully installed dgl-cu101-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ricDsel0wdyY"
      },
      "source": [
        "### Setting the environnement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9qiMN-gwXAM"
      },
      "source": [
        "import argparse\r\n",
        "from os import path\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torch.nn.functional as F\r\n",
        "from dgl import batch\r\n",
        "from dgl.data.ppi import LegacyPPIDataset\r\n",
        "from dgl.nn.pytorch import GraphConv\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from torch import nn, optim\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "\r\n",
        "JUPYTER = True\r\n",
        "\r\n",
        "MODEL_STATE_FILE = 0\r\n",
        "if JUPYTER:\r\n",
        "    import os\r\n",
        "    path = \"\"\r\n",
        "    MODEL_STATE_FILE = path.join((os.path.abspath(''), \"/model_state.pth\"))\r\n",
        "    MODEL_STATE_FILE = \"model_state.pth\"\r\n",
        "else:\r\n",
        "    MODEL_STATE_FILE = path.join(path.dirname(path.abspath(__file__)), \"model_state.pth\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAfuSjChwYgI"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8PnkmzfKbU9",
        "outputId": "5729bb97-1db3-4c0d-f972-7b507ff1c250"
      },
      "source": [
        "class BasicGraphModel(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, g, n_layers, input_size, hidden_size, output_size, nonlinearity):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.g = g\r\n",
        "        self.layers = nn.ModuleList()\r\n",
        "        self.layers.append(\r\n",
        "            GraphConv(input_size, hidden_size, activation=nonlinearity))\r\n",
        "        for i in range(n_layers - 1):\r\n",
        "            self.layers.append(\r\n",
        "                GraphConv(hidden_size, hidden_size, activation=nonlinearity))\r\n",
        "        self.layers.append(GraphConv(hidden_size, output_size))\r\n",
        "\r\n",
        "    def forward(self, inputs):\r\n",
        "        outputs = inputs\r\n",
        "        for i, layer in enumerate(self.layers):\r\n",
        "            outputs = layer(self.g, outputs)\r\n",
        "        return outputs\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZyJGHWAwq-H"
      },
      "source": [
        "### Main, Train, Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHA8kv63wlah"
      },
      "source": [
        "\r\n",
        "def main(args):\r\n",
        "    # create the dataset\r\n",
        "    train_dataset, test_dataset = LegacyPPIDataset(\r\n",
        "        mode=\"train\"), LegacyPPIDataset(mode=\"test\")\r\n",
        "    train_dataloader = DataLoader(\r\n",
        "        train_dataset, batch_size=args.batch_size, collate_fn=collate_fn)\r\n",
        "    test_dataloader = DataLoader(\r\n",
        "        test_dataset, batch_size=args.batch_size, collate_fn=collate_fn)\r\n",
        "    n_features, n_classes = train_dataset.features.shape[1], train_dataset.labels.shape[1]\r\n",
        "\r\n",
        "    # create the model, loss function and optimizer\r\n",
        "    device = torch.device(\"cpu\" if args.gpu < 0 else \"cuda:\" + str(args.gpu))\r\n",
        "    model = BasicGraphModel(g=train_dataset.graph, n_layers=2, input_size=n_features,\r\n",
        "                            hidden_size=256, output_size=n_classes, nonlinearity=F.elu).to(device)\r\n",
        "    loss_fcn = nn.BCEWithLogitsLoss()\r\n",
        "    optimizer = torch.optim.Adam(model.parameters())\r\n",
        "\r\n",
        "    # train and test\r\n",
        "    if args.mode == \"train\":\r\n",
        "        train(model, loss_fcn, device, optimizer,\r\n",
        "              train_dataloader, test_dataset)\r\n",
        "        torch.save(model.state_dict(), MODEL_STATE_FILE)\r\n",
        "    model.load_state_dict(torch.load(MODEL_STATE_FILE))\r\n",
        "    return test(model, loss_fcn, device, test_dataloader)\r\n",
        "\r\n",
        "\r\n",
        "def train(model, loss_fcn, device, optimizer, train_dataloader, test_dataset):\r\n",
        "    for epoch in range(args.epochs):\r\n",
        "        model.train()\r\n",
        "        losses = []\r\n",
        "        for batch, data in enumerate(train_dataloader):\r\n",
        "            subgraph, features, labels = data\r\n",
        "            features = features.to(device)\r\n",
        "            labels = labels.to(device)\r\n",
        "            model.g = subgraph\r\n",
        "            for layer in model.layers:\r\n",
        "                layer.g = subgraph\r\n",
        "            logits = model(features.float())\r\n",
        "            loss = loss_fcn(logits, labels.float())\r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            losses.append(loss.item())\r\n",
        "        loss_data = np.array(losses).mean()\r\n",
        "        print(\"Epoch {:05d} | Loss: {:.4f}\".format(epoch + 1, loss_data))\r\n",
        "\r\n",
        "        if epoch % 5 == 0:\r\n",
        "            scores = []\r\n",
        "            for batch, test_data in enumerate(test_dataset):\r\n",
        "                subgraph, features, labels = test_data\r\n",
        "                features = features.clone().detach().to(device)\r\n",
        "                labels = labels.clone().detach().to(device)\r\n",
        "                score, _ = evaluate(features.float(), model,\r\n",
        "                                    subgraph, labels.float(), loss_fcn)\r\n",
        "                scores.append(score)\r\n",
        "            print(\"F1-Score: {:.4f} \".format(np.array(scores).mean()))\r\n",
        "\r\n",
        "\r\n",
        "def test(model, loss_fcn, device, test_dataloader):\r\n",
        "    test_scores = []\r\n",
        "    for batch, test_data in enumerate(test_dataloader):\r\n",
        "        subgraph, features, labels = test_data\r\n",
        "        features = features.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "        test_scores.append(\r\n",
        "            evaluate(features, model, subgraph, labels.float(), loss_fcn)[0])\r\n",
        "    mean_scores = np.array(test_scores).mean()\r\n",
        "    print(\"F1-Score: {:.4f}\".format(np.array(test_scores).mean()))\r\n",
        "    return mean_scores\r\n",
        "\r\n",
        "\r\n",
        "def evaluate(features, model, subgraph, labels, loss_fcn):\r\n",
        "    with torch.no_grad():\r\n",
        "        model.eval()\r\n",
        "        model.g = subgraph\r\n",
        "        for layer in model.layers:\r\n",
        "            layer.g = subgraph\r\n",
        "        output = model(features.float())\r\n",
        "        loss_data = loss_fcn(output, labels.float())\r\n",
        "        predict = np.where(output.data.cpu().numpy() >= 0.5, 1, 0)\r\n",
        "        score = f1_score(labels.data.cpu().numpy(), predict, average=\"micro\")\r\n",
        "        return score, loss_data.item()\r\n",
        "\r\n",
        "\r\n",
        "def collate_fn(sample):\r\n",
        "    graphs, features, labels = map(list, zip(*sample))\r\n",
        "    graph = batch(graphs)\r\n",
        "    features = torch.from_numpy(np.concatenate(features))\r\n",
        "    labels = torch.from_numpy(np.concatenate(labels))\r\n",
        "    return graph, features, labels\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJlHw_JJwwLa"
      },
      "source": [
        "### Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKazbtjwMA0A",
        "outputId": "f688fdbc-debc-4363-abfd-b0fb82c14389"
      },
      "source": [
        "if not JUPYTER:\r\n",
        "    # We are in a notebook and not in a python file    \r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "    parser.add_argument(\"--mode\",  choices=[\"train\", \"test\"], default=\"train\")\r\n",
        "    parser.add_argument(\"--gpu\", type=int, default=-1,\r\n",
        "                        help=\"GPU to use. Set -1 to use CPU.\")\r\n",
        "    parser.add_argument(\"--epochs\", type=int, default=250)\r\n",
        "    parser.add_argument(\"--batch-size\", type=int, default=2)\r\n",
        "\r\n",
        "    args = parser.parse_args()\r\n",
        "    main(args)\r\n",
        "else:\r\n",
        "    class Args:\r\n",
        "        mode = \"train\"\r\n",
        "        # \"cpu\" if args.gpu < 0 else \"cuda:\" + str(args.gpu)\r\n",
        "        gpu = -1\r\n",
        "        epochs = 20\r\n",
        "        batch_size = 2\r\n",
        "\r\n",
        "    args=Args()\r\n",
        "    main(args)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.features will be deprecated, please use dataset.graphs[i].ndata['feat'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.labels will be deprecated, please use dataset.graphs[i].ndata['label'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00001 | Loss: 0.6870\n",
            "F1-Score: 0.0010 \n",
            "Epoch 00002 | Loss: 0.6523\n",
            "Epoch 00003 | Loss: 0.6056\n",
            "Epoch 00004 | Loss: 0.5915\n",
            "Epoch 00005 | Loss: 0.5808\n",
            "Epoch 00006 | Loss: 0.5738\n",
            "F1-Score: 0.3369 \n",
            "Epoch 00007 | Loss: 0.5681\n",
            "Epoch 00008 | Loss: 0.5642\n",
            "Epoch 00009 | Loss: 0.5611\n",
            "Epoch 00010 | Loss: 0.5588\n",
            "Epoch 00011 | Loss: 0.5570\n",
            "F1-Score: 0.3670 \n",
            "Epoch 00012 | Loss: 0.5554\n",
            "Epoch 00013 | Loss: 0.5540\n",
            "Epoch 00014 | Loss: 0.5527\n",
            "Epoch 00015 | Loss: 0.5514\n",
            "Epoch 00016 | Loss: 0.5502\n",
            "F1-Score: 0.3725 \n",
            "Epoch 00017 | Loss: 0.5490\n",
            "Epoch 00018 | Loss: 0.5479\n",
            "Epoch 00019 | Loss: 0.5468\n",
            "Epoch 00020 | Loss: 0.5457\n",
            "F1-Score: 0.3773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT5-CNBzfpE1",
        "outputId": "9e031af8-f3b6-424e-e932-f01ef54bcb7d"
      },
      "source": [
        "class Args:\r\n",
        "        mode = \"test\"\r\n",
        "        # \"cpu\" if args.gpu < 0 else \"cuda:\" + str(args.gpu)\r\n",
        "        # For some reason, gpu = 0 does not work.\r\n",
        "        gpu = -1\r\n",
        "        epochs = 20\r\n",
        "        batch_size = 2\r\n",
        "\r\n",
        "args=Args()\r\n",
        "main(args)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.features will be deprecated, please use dataset.graphs[i].ndata['feat'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.labels will be deprecated, please use dataset.graphs[i].ndata['label'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1-Score: 0.3773\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37725352297478154"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j_Kyao4vlMB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}