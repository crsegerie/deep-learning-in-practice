{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP3_Graphs_final.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK0qOkzJKjP2",
        "outputId": "cdb396fb-702c-4624-b95a-3e26a8307496"
      },
      "source": [
        "# ! pip install dgl           # For CPU Build\r\n",
        "! pip install dgl-cu101     # For CUDA 10.1 Build\r\n",
        "\r\n",
        "# Do not forget to put manually colab in gpu mode"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dgl-cu101\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/08/ea2d56e85eba1c22a14fa0f9b3c4ca8b43bf07de34e454d4e23632b376ea/dgl_cu101-0.5.3-cp36-cp36m-manylinux1_x86_64.whl (25.0MB)\n",
            "\u001b[K     |████████████████████████████████| 25.0MB 121kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl-cu101) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from dgl-cu101) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl-cu101) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl-cu101) (2.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl-cu101) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl-cu101) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl-cu101) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl-cu101) (3.0.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl-cu101) (4.4.2)\n",
            "Installing collected packages: dgl-cu101\n",
            "Successfully installed dgl-cu101-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDVgV9SzC_Mc",
        "outputId": "c7169dfa-150f-42fb-a102-94367679c6ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeoGWap0B0jU",
        "outputId": "17c7f85d-55c9-45a1-a887-00eddeb69766"
      },
      "source": [
        "!python train_ppi_baseline.py --gpu 0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Using backend: pytorch\n",
            "Downloading /root/.dgl/ppi.zip from https://data.dgl.ai/dataset/ppi.zip...\n",
            "Extracting file to /root/.dgl/ppi\n",
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.features will be deprecated, please use dataset.graphs[i].ndata['feat'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.labels will be deprecated, please use dataset.graphs[i].ndata['label'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "n_features 50\n",
            "n_classes 121\n",
            "Epoch 00001 | Loss: 0.7003\n",
            "F1-Score: 0.3092 \n",
            "Epoch 00002 | Loss: 0.6828\n",
            "Epoch 00003 | Loss: 0.6814\n",
            "Epoch 00004 | Loss: 0.6813\n",
            "Epoch 00005 | Loss: 0.6810\n",
            "Epoch 00006 | Loss: 0.6808\n",
            "F1-Score: 0.3244 \n",
            "Epoch 00007 | Loss: 0.6805\n",
            "Epoch 00008 | Loss: 0.6802\n",
            "Epoch 00009 | Loss: 0.6798\n",
            "Epoch 00010 | Loss: 0.6794\n",
            "Epoch 00011 | Loss: 0.6790\n",
            "F1-Score: 0.3381 \n",
            "Epoch 00012 | Loss: 0.6785\n",
            "Epoch 00013 | Loss: 0.6781\n",
            "Epoch 00014 | Loss: 0.6774\n",
            "Epoch 00015 | Loss: 0.6765\n",
            "Epoch 00016 | Loss: 0.6759\n",
            "F1-Score: 0.3745 \n",
            "Epoch 00017 | Loss: 0.6758\n",
            "Epoch 00018 | Loss: 0.6745\n",
            "Epoch 00019 | Loss: 0.6736\n",
            "Epoch 00020 | Loss: 0.6725\n",
            "Epoch 00021 | Loss: 0.6711\n",
            "F1-Score: 0.4013 \n",
            "Epoch 00022 | Loss: 0.6688\n",
            "Epoch 00023 | Loss: 0.6661\n",
            "Epoch 00024 | Loss: 0.6717\n",
            "Epoch 00025 | Loss: 0.6742\n",
            "Epoch 00026 | Loss: 0.6710\n",
            "F1-Score: 0.4084 \n",
            "Epoch 00027 | Loss: 0.6683\n",
            "Epoch 00028 | Loss: 0.6661\n",
            "Epoch 00029 | Loss: 0.6639\n",
            "Epoch 00030 | Loss: 0.6617\n",
            "Epoch 00031 | Loss: 0.6615\n",
            "F1-Score: 0.4869 \n",
            "Epoch 00032 | Loss: 0.6576\n",
            "Epoch 00033 | Loss: 0.6551\n",
            "Epoch 00034 | Loss: 0.6526\n",
            "Epoch 00035 | Loss: 0.6488\n",
            "Epoch 00036 | Loss: 0.6481\n",
            "F1-Score: 0.6101 \n",
            "Epoch 00037 | Loss: 0.6455\n",
            "Epoch 00038 | Loss: 0.6434\n",
            "Epoch 00039 | Loss: 0.6414\n",
            "Epoch 00040 | Loss: 0.6387\n",
            "Epoch 00041 | Loss: 0.6353\n",
            "F1-Score: 0.7038 \n",
            "Epoch 00042 | Loss: 0.6327\n",
            "Epoch 00043 | Loss: 0.6304\n",
            "Epoch 00044 | Loss: 0.6283\n",
            "Epoch 00045 | Loss: 0.6259\n",
            "Epoch 00046 | Loss: 0.6239\n",
            "F1-Score: 0.7725 \n",
            "Epoch 00047 | Loss: 0.6229\n",
            "Epoch 00048 | Loss: 0.6211\n",
            "Epoch 00049 | Loss: 0.6204\n",
            "Epoch 00050 | Loss: 0.6183\n",
            "Epoch 00051 | Loss: 0.6164\n",
            "F1-Score: 0.8161 \n",
            "Epoch 00052 | Loss: 0.6137\n",
            "Epoch 00053 | Loss: 0.6113\n",
            "Epoch 00054 | Loss: 0.6097\n",
            "Epoch 00055 | Loss: 0.6087\n",
            "Epoch 00056 | Loss: 0.6075\n",
            "F1-Score: 0.8603 \n",
            "Epoch 00057 | Loss: 0.6063\n",
            "Epoch 00058 | Loss: 0.6051\n",
            "Epoch 00059 | Loss: 0.6038\n",
            "Epoch 00060 | Loss: 0.6026\n",
            "Epoch 00061 | Loss: 0.6014\n",
            "F1-Score: 0.8842 \n",
            "Epoch 00062 | Loss: 0.6004\n",
            "Epoch 00063 | Loss: 0.5993\n",
            "Epoch 00064 | Loss: 0.5984\n",
            "Epoch 00065 | Loss: 0.5977\n",
            "Epoch 00066 | Loss: 0.5970\n",
            "F1-Score: 0.9055 \n",
            "Epoch 00067 | Loss: 0.5962\n",
            "Epoch 00068 | Loss: 0.5954\n",
            "Epoch 00069 | Loss: 0.5947\n",
            "Epoch 00070 | Loss: 0.5940\n",
            "Epoch 00071 | Loss: 0.5931\n",
            "F1-Score: 0.9230 \n",
            "Epoch 00072 | Loss: 0.5922\n",
            "Epoch 00073 | Loss: 0.5916\n",
            "Epoch 00074 | Loss: 0.5911\n",
            "Epoch 00075 | Loss: 0.5907\n",
            "Epoch 00076 | Loss: 0.5904\n",
            "F1-Score: 0.9341 \n",
            "Epoch 00077 | Loss: 0.5899\n",
            "Epoch 00078 | Loss: 0.5894\n",
            "Epoch 00079 | Loss: 0.5888\n",
            "Epoch 00080 | Loss: 0.5883\n",
            "Epoch 00081 | Loss: 0.5879\n",
            "F1-Score: 0.9457 \n",
            "Epoch 00082 | Loss: 0.5875\n",
            "Epoch 00083 | Loss: 0.5871\n",
            "Epoch 00084 | Loss: 0.5868\n",
            "Epoch 00085 | Loss: 0.5865\n",
            "Epoch 00086 | Loss: 0.5860\n",
            "F1-Score: 0.9538 \n",
            "Epoch 00087 | Loss: 0.5856\n",
            "Epoch 00088 | Loss: 0.5852\n",
            "Epoch 00089 | Loss: 0.5849\n",
            "Epoch 00090 | Loss: 0.5845\n",
            "Epoch 00091 | Loss: 0.5842\n",
            "F1-Score: 0.9598 \n",
            "Epoch 00092 | Loss: 0.5838\n",
            "Epoch 00093 | Loss: 0.5835\n",
            "Epoch 00094 | Loss: 0.5832\n",
            "Epoch 00095 | Loss: 0.5828\n",
            "Epoch 00096 | Loss: 0.5826\n",
            "F1-Score: 0.9668 \n",
            "Epoch 00097 | Loss: 0.5824\n",
            "Epoch 00098 | Loss: 0.5823\n",
            "Epoch 00099 | Loss: 0.5821\n",
            "Epoch 00100 | Loss: 0.5820\n",
            "Epoch 00101 | Loss: 0.5819\n",
            "F1-Score: 0.9699 \n",
            "Epoch 00102 | Loss: 0.5818\n",
            "Epoch 00103 | Loss: 0.5817\n",
            "Epoch 00104 | Loss: 0.5817\n",
            "Epoch 00105 | Loss: 0.5816\n",
            "Epoch 00106 | Loss: 0.5815\n",
            "F1-Score: 0.9700 \n",
            "Epoch 00107 | Loss: 0.5813\n",
            "Epoch 00108 | Loss: 0.5811\n",
            "Epoch 00109 | Loss: 0.5810\n",
            "Epoch 00110 | Loss: 0.5808\n",
            "Epoch 00111 | Loss: 0.5806\n",
            "F1-Score: 0.9736 \n",
            "Epoch 00112 | Loss: 0.5805\n",
            "Epoch 00113 | Loss: 0.5805\n",
            "Epoch 00114 | Loss: 0.5804\n",
            "Epoch 00115 | Loss: 0.5804\n",
            "Epoch 00116 | Loss: 0.5803\n",
            "F1-Score: 0.9750 \n",
            "Epoch 00117 | Loss: 0.5802\n",
            "Epoch 00118 | Loss: 0.5802\n",
            "Epoch 00119 | Loss: 0.5801\n",
            "Epoch 00120 | Loss: 0.5800\n",
            "Epoch 00121 | Loss: 0.5799\n",
            "F1-Score: 0.9757 \n",
            "Epoch 00122 | Loss: 0.5798\n",
            "Epoch 00123 | Loss: 0.5798\n",
            "Epoch 00124 | Loss: 0.5797\n",
            "Epoch 00125 | Loss: 0.5797\n",
            "Epoch 00126 | Loss: 0.5796\n",
            "F1-Score: 0.9764 \n",
            "Epoch 00127 | Loss: 0.5796\n",
            "Epoch 00128 | Loss: 0.5796\n",
            "Epoch 00129 | Loss: 0.5795\n",
            "Epoch 00130 | Loss: 0.5795\n",
            "Epoch 00131 | Loss: 0.5794\n",
            "F1-Score: 0.9777 \n",
            "Epoch 00132 | Loss: 0.5793\n",
            "Epoch 00133 | Loss: 0.5792\n",
            "Epoch 00134 | Loss: 0.5791\n",
            "Epoch 00135 | Loss: 0.5790\n",
            "Epoch 00136 | Loss: 0.5789\n",
            "F1-Score: 0.9798 \n",
            "Epoch 00137 | Loss: 0.5788\n",
            "Epoch 00138 | Loss: 0.5788\n",
            "Epoch 00139 | Loss: 0.5787\n",
            "Epoch 00140 | Loss: 0.5787\n",
            "Epoch 00141 | Loss: 0.5787\n",
            "F1-Score: 0.9806 \n",
            "Epoch 00142 | Loss: 0.5786\n",
            "Epoch 00143 | Loss: 0.5786\n",
            "Epoch 00144 | Loss: 0.5786\n",
            "Epoch 00145 | Loss: 0.5785\n",
            "Epoch 00146 | Loss: 0.5785\n",
            "F1-Score: 0.9812 \n",
            "Epoch 00147 | Loss: 0.5785\n",
            "Epoch 00148 | Loss: 0.5784\n",
            "Epoch 00149 | Loss: 0.5784\n",
            "Epoch 00150 | Loss: 0.5784\n",
            "Epoch 00151 | Loss: 0.5784\n",
            "F1-Score: 0.9816 \n",
            "Epoch 00152 | Loss: 0.5784\n",
            "Epoch 00153 | Loss: 0.5783\n",
            "Epoch 00154 | Loss: 0.5783\n",
            "Epoch 00155 | Loss: 0.5783\n",
            "Epoch 00156 | Loss: 0.5783\n",
            "F1-Score: 0.9819 \n",
            "Epoch 00157 | Loss: 0.5783\n",
            "Epoch 00158 | Loss: 0.5783\n",
            "Epoch 00159 | Loss: 0.5782\n",
            "Epoch 00160 | Loss: 0.5782\n",
            "Epoch 00161 | Loss: 0.5782\n",
            "F1-Score: 0.9821 \n",
            "Epoch 00162 | Loss: 0.5782\n",
            "Epoch 00163 | Loss: 0.5782\n",
            "Epoch 00164 | Loss: 0.5782\n",
            "Epoch 00165 | Loss: 0.5782\n",
            "Epoch 00166 | Loss: 0.5782\n",
            "F1-Score: 0.9823 \n",
            "Epoch 00167 | Loss: 0.5782\n",
            "Epoch 00168 | Loss: 0.5781\n",
            "Epoch 00169 | Loss: 0.5781\n",
            "Epoch 00170 | Loss: 0.5781\n",
            "Epoch 00171 | Loss: 0.5781\n",
            "F1-Score: 0.9825 \n",
            "Epoch 00172 | Loss: 0.5781\n",
            "Epoch 00173 | Loss: 0.5781\n",
            "Epoch 00174 | Loss: 0.5781\n",
            "Epoch 00175 | Loss: 0.5781\n",
            "Epoch 00176 | Loss: 0.5781\n",
            "F1-Score: 0.9827 \n",
            "Epoch 00177 | Loss: 0.5781\n",
            "Epoch 00178 | Loss: 0.5781\n",
            "Epoch 00179 | Loss: 0.5780\n",
            "Epoch 00180 | Loss: 0.5780\n",
            "Epoch 00181 | Loss: 0.5780\n",
            "F1-Score: 0.9828 \n",
            "Epoch 00182 | Loss: 0.5780\n",
            "Epoch 00183 | Loss: 0.5780\n",
            "Epoch 00184 | Loss: 0.5780\n",
            "Epoch 00185 | Loss: 0.5780\n",
            "Epoch 00186 | Loss: 0.5780\n",
            "F1-Score: 0.9830 \n",
            "Epoch 00187 | Loss: 0.5780\n",
            "Epoch 00188 | Loss: 0.5780\n",
            "Epoch 00189 | Loss: 0.5780\n",
            "Epoch 00190 | Loss: 0.5780\n",
            "Epoch 00191 | Loss: 0.5779\n",
            "F1-Score: 0.9831 \n",
            "Epoch 00192 | Loss: 0.5779\n",
            "Epoch 00193 | Loss: 0.5779\n",
            "Epoch 00194 | Loss: 0.5779\n",
            "Epoch 00195 | Loss: 0.5779\n",
            "Epoch 00196 | Loss: 0.5779\n",
            "F1-Score: 0.9833 \n",
            "Epoch 00197 | Loss: 0.5779\n",
            "Epoch 00198 | Loss: 0.5779\n",
            "Epoch 00199 | Loss: 0.5779\n",
            "Epoch 00200 | Loss: 0.5779\n",
            "Epoch 00201 | Loss: 0.5779\n",
            "F1-Score: 0.9833 \n",
            "Epoch 00202 | Loss: 0.5779\n",
            "Epoch 00203 | Loss: 0.5779\n",
            "Epoch 00204 | Loss: 0.5779\n",
            "Epoch 00205 | Loss: 0.5779\n",
            "Epoch 00206 | Loss: 0.5779\n",
            "F1-Score: 0.9833 \n",
            "Epoch 00207 | Loss: 0.5779\n",
            "Epoch 00208 | Loss: 0.5778\n",
            "Epoch 00209 | Loss: 0.5778\n",
            "Epoch 00210 | Loss: 0.5778\n",
            "Epoch 00211 | Loss: 0.5778\n",
            "F1-Score: 0.9835 \n",
            "Epoch 00212 | Loss: 0.5778\n",
            "Epoch 00213 | Loss: 0.5778\n",
            "Epoch 00214 | Loss: 0.5778\n",
            "Epoch 00215 | Loss: 0.5778\n",
            "Epoch 00216 | Loss: 0.5778\n",
            "F1-Score: 0.9837 \n",
            "Epoch 00217 | Loss: 0.5778\n",
            "Epoch 00218 | Loss: 0.5778\n",
            "Epoch 00219 | Loss: 0.5778\n",
            "Epoch 00220 | Loss: 0.5778\n",
            "Epoch 00221 | Loss: 0.5778\n",
            "F1-Score: 0.9837 \n",
            "Epoch 00222 | Loss: 0.5778\n",
            "Epoch 00223 | Loss: 0.5778\n",
            "Epoch 00224 | Loss: 0.5777\n",
            "Epoch 00225 | Loss: 0.5777\n",
            "Epoch 00226 | Loss: 0.5777\n",
            "F1-Score: 0.9838 \n",
            "Epoch 00227 | Loss: 0.5777\n",
            "Epoch 00228 | Loss: 0.5777\n",
            "Epoch 00229 | Loss: 0.5777\n",
            "Epoch 00230 | Loss: 0.5777\n",
            "Epoch 00231 | Loss: 0.5777\n",
            "F1-Score: 0.9838 \n",
            "Epoch 00232 | Loss: 0.5777\n",
            "Epoch 00233 | Loss: 0.5777\n",
            "Epoch 00234 | Loss: 0.5777\n",
            "Epoch 00235 | Loss: 0.5777\n",
            "Epoch 00236 | Loss: 0.5777\n",
            "F1-Score: 0.9839 \n",
            "Epoch 00237 | Loss: 0.5777\n",
            "Epoch 00238 | Loss: 0.5777\n",
            "Epoch 00239 | Loss: 0.5777\n",
            "Epoch 00240 | Loss: 0.5777\n",
            "Epoch 00241 | Loss: 0.5777\n",
            "F1-Score: 0.9839 \n",
            "Epoch 00242 | Loss: 0.5777\n",
            "Epoch 00243 | Loss: 0.5777\n",
            "Epoch 00244 | Loss: 0.5777\n",
            "Epoch 00245 | Loss: 0.5777\n",
            "Epoch 00246 | Loss: 0.5777\n",
            "F1-Score: 0.9840 \n",
            "Epoch 00247 | Loss: 0.5777\n",
            "Epoch 00248 | Loss: 0.5777\n",
            "Epoch 00249 | Loss: 0.5777\n",
            "Epoch 00250 | Loss: 0.5777\n",
            "F1-Score: 0.9827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-62VkoxE5eU",
        "outputId": "e1d468dd-d2b2-4a58-f973-296cb4345f11"
      },
      "source": [
        "!python train_ppi.py --mode test"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using backend: pytorch\n",
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.features will be deprecated, please use dataset.graphs[i].ndata['feat'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.labels will be deprecated, please use dataset.graphs[i].ndata['label'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "n_features 50\n",
            "n_classes 121\n",
            "F1-Score: 0.9827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqYSo4w-FBRi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}